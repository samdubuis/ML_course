{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: surprise in /home/samuel/.local/lib/python3.7/site-packages (0.1)\n",
      "Requirement already satisfied: scikit-surprise in /home/samuel/.local/lib/python3.7/site-packages (from surprise) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.11.2 in /home/samuel/.local/lib/python3.7/site-packages (from scikit-surprise->surprise) (1.17.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/lib/python3/dist-packages (from scikit-surprise->surprise) (1.12.0)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/samuel/.local/lib/python3.7/site-packages (from scikit-surprise->surprise) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/samuel/.local/lib/python3.7/site-packages (from scikit-surprise->surprise) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "!pip3 install surprise\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "\n",
    "from surprise import SVD, KNNBasic, NMF, SlopeOne, CoClustering #other knn, randoms, not svdpp because were not doing implicit               # importer ici les algo qu'on testera\n",
    "from surprise import model_selection\n",
    "from surprise import dump\n",
    "\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Prediction</th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>r44_c1</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>r61_c1</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>r67_c1</td>\n",
       "      <td>4</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>r72_c1</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>r86_c1</td>\n",
       "      <td>5</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1176947</td>\n",
       "      <td>r9990_c1000</td>\n",
       "      <td>4</td>\n",
       "      <td>9990</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1176948</td>\n",
       "      <td>r9992_c1000</td>\n",
       "      <td>5</td>\n",
       "      <td>9992</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1176949</td>\n",
       "      <td>r9994_c1000</td>\n",
       "      <td>3</td>\n",
       "      <td>9994</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1176950</td>\n",
       "      <td>r9997_c1000</td>\n",
       "      <td>4</td>\n",
       "      <td>9997</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1176951</td>\n",
       "      <td>r10000_c1000</td>\n",
       "      <td>3</td>\n",
       "      <td>10000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1176952 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Id  Prediction   user  item\n",
       "0              r44_c1           4     44     1\n",
       "1              r61_c1           3     61     1\n",
       "2              r67_c1           4     67     1\n",
       "3              r72_c1           3     72     1\n",
       "4              r86_c1           5     86     1\n",
       "...               ...         ...    ...   ...\n",
       "1176947   r9990_c1000           4   9990  1000\n",
       "1176948   r9992_c1000           5   9992  1000\n",
       "1176949   r9994_c1000           3   9994  1000\n",
       "1176950   r9997_c1000           4   9997  1000\n",
       "1176951  r10000_c1000           3  10000  1000\n",
       "\n",
       "[1176952 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"Datasets/data_train.csv\")\n",
    "\n",
    "df[[\"user\", \"item\"]] = df.Id.str.split(\"_\", expand=True)\n",
    "\n",
    "df.user = df.user.str.replace(\"r\", \"\")\n",
    "df.item = df.item.str.replace(\"c\", \"\")\n",
    "\n",
    "#########\n",
    "df2 = pd.read_csv(\"Datasets/sample_submission.csv\")\n",
    "\n",
    "df2[[\"user\", \"item\"]] = df2.Id.str.split(\"_\", expand=True)\n",
    "\n",
    "df2.user = df2.user.str.replace(\"r\", \"\")\n",
    "df2.item = df2.item.str.replace(\"c\", \"\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fifth, test = train_test_split(df, test_size=0.8, random_state=1)\n",
    "df_hundredth,test = train_test_split(df, test_size=0.99, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(1,5)) \n",
    "data = Dataset.load_from_df(df[[\"user\",\"item\",\"Prediction\"]], reader)\n",
    "data_fifth = Dataset.load_from_df(df_fifth[[\"user\",\"item\",\"Prediction\"]], reader)\n",
    "data_hundredth = Dataset.load_from_df(df_hundredth[[\"user\",\"item\",\"Prediction\"]], reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df#freeing memory\n",
    "del df_fifth\n",
    "del df_hundredth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-5)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-5)]: Done   2 out of   5 | elapsed:    1.1s remaining:    1.7s\n",
      "[Parallel(n_jobs=-5)]: Done   3 out of   5 | elapsed:    1.4s remaining:    0.9s\n",
      "[Parallel(n_jobs=-5)]: Done   5 out of   5 | elapsed:    1.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-5)]: Done   5 out of   5 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': {'n_factors': 10, 'n_epochs': 20, 'lr_all': 0.003, 'reg_all': 0.05}}\n",
      "{'rmse': 1.061329011710672}\n",
      "The dump has been saved as file dump/SVDfitted_dump\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_factors' : [10],\n",
    "    'n_epochs': [20],\n",
    "    'lr_all': [0.003],\n",
    "    'reg_all': [0.05]\n",
    "} \n",
    "cv=5\n",
    "algorithm = SVD\n",
    "\n",
    "gs = model_selection.GridSearchCV(algorithm, param_grid, measures=['rmse'], cv=cv, n_jobs=-5, joblib_verbose=10)  #enlever mae car non utilisé dans le projet pour sauver du temps\n",
    "gs.fit(data_hundredth)\n",
    "print(gs.best_params)\n",
    "print(gs.best_score)\n",
    "algo = gs.best_estimator[\"rmse\"]\n",
    "algo.fit(data.build_full_trainset())\n",
    "dump.dump(\"dump/SVDfitted_dump\", algo=algo, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-5)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-5)]: Done   5 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=-5)]: Done  10 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=-5)]: Done  16 out of  20 | elapsed:   15.9s remaining:    4.0s\n",
      "[Parallel(n_jobs=-5)]: Done  20 out of  20 | elapsed:   17.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': {'k': 40, 'min_k': 3}}\n",
      "{'rmse': 1.117062845195538}\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "The dump has been saved as file dump/KNN_basic_fitted_dump\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'k' : [40,100],\n",
    "    'min_k': [1,3]\n",
    "} \n",
    "cv=5\n",
    "algorithm = KNNBasic\n",
    "\n",
    "gs = model_selection.GridSearchCV(algorithm, param_grid, measures=['rmse'], cv=cv, n_jobs=-5, joblib_verbose=10)  #enlever mae car non utilisé dans le projet pour sauver du temps\n",
    "gs.fit(data_hundredth)\n",
    "print(gs.best_params)\n",
    "print(gs.best_score)\n",
    "algo = gs.best_estimator[\"rmse\"]\n",
    "algo.fit(data.build_full_trainset())\n",
    "dump.dump(\"dump/KNN_basic_fitted_dump\", algo=algo, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-5)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-5)]: Done   2 out of   5 | elapsed:    1.9s remaining:    2.9s\n",
      "[Parallel(n_jobs=-5)]: Done   3 out of   5 | elapsed:    2.3s remaining:    1.5s\n",
      "[Parallel(n_jobs=-5)]: Done   5 out of   5 | elapsed:    2.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-5)]: Done   5 out of   5 | elapsed:    2.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': {'n_factors': 15, 'n_epochs': 50}}\n",
      "{'rmse': 1.3240168225571949}\n",
      "The dump has been saved as file dump/NMFfitted_dump\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_factors' : [15],\n",
    "    'n_epochs': [50]\n",
    "} \n",
    "cv=5\n",
    "algorithm = NMF\n",
    "\n",
    "gs = model_selection.GridSearchCV(algorithm, param_grid, measures=['rmse'], cv=cv, n_jobs=-5, joblib_verbose=10)  #enlever mae car non utilisé dans le projet pour sauver du temps\n",
    "gs.fit(data_hundredth)\n",
    "print(gs.best_params)\n",
    "print(gs.best_score)\n",
    "algo = gs.best_estimator[\"rmse\"]\n",
    "algo.fit(data.build_full_trainset())\n",
    "dump.dump(\"dump/NMFfitted_dump\", algo=algo, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SlopeOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dump has been saved as file dump/SlopeOne_fitted_dump\n"
     ]
    }
   ],
   "source": [
    "algo = SlopeOne()\n",
    "algo.fit(data.build_full_trainset())\n",
    "dump.dump(\"dump/SlopeOne_fitted_dump\", algo=algo, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CoClustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-5)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-5)]: Done   2 out of   5 | elapsed:    3.5s remaining:    5.2s\n",
      "[Parallel(n_jobs=-5)]: Done   3 out of   5 | elapsed:    3.8s remaining:    2.5s\n",
      "[Parallel(n_jobs=-5)]: Done   5 out of   5 | elapsed:    4.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-5)]: Done   5 out of   5 | elapsed:    4.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rmse': {'n_cltr_u': 3, 'n_cltr_i': 3, 'n_epochs': 50}}\n",
      "{'rmse': 1.2605553912494378}\n",
      "The dump has been saved as file dump/CoClustering_fitted_dump\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_cltr_u' : [3],\n",
    "    'n_cltr_i' : [3], \n",
    "    'n_epochs': [50]\n",
    "} \n",
    "cv=5\n",
    "algorithm = CoClustering\n",
    "\n",
    "gs = model_selection.GridSearchCV(algorithm, param_grid, measures=['rmse'], cv=cv, n_jobs=-5, joblib_verbose=10)  #enlever mae car non utilisé dans le projet pour sauver du temps\n",
    "gs.fit(data_hundredth)\n",
    "print(gs.best_params)\n",
    "print(gs.best_score)\n",
    "algo = gs.best_estimator[\"rmse\"]\n",
    "algo.fit(data.build_full_trainset())\n",
    "dump.dump(\"dump/CoClustering_fitted_dump\", algo=algo, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "del algo, gs\n",
    "\n",
    "array_SVD = np.ones((df2.shape[0],1))\n",
    "array_KNN = np.ones((df2.shape[0],1))\n",
    "array_NMF = np.ones((df2.shape[0],1))\n",
    "array_SlopeOne = np.ones((df2.shape[0],1))\n",
    "array_CoClustering = np.ones((df2.shape[0],1))\n",
    "\n",
    "_, algo_svd = dump.load(\"dump/SVDfitted_dump\")\n",
    "_, algo_knn = dump.load(\"dump/KNN_basic_fitted_dump\")\n",
    "_, algo_nmf = dump.load(\"dump/NMFfitted_dump\")\n",
    "_, algo_slopeone = dump.load(\"dump/SlopeOne_fitted_dump\")\n",
    "_, algo_coclustering = dump.load(\"dump/CoClustering_fitted_dump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n",
      "600000\n",
      "700000\n",
      "800000\n",
      "900000\n",
      "1000000\n",
      "1100000\n"
     ]
    }
   ],
   "source": [
    "knn_fail = 0\n",
    "slopeone_fail = 0\n",
    "\n",
    "for i in df2.iterrows():\n",
    "    array_SVD[i[0]] = algo_svd.estimate(int(i[1][2]), int(i[1][3]))\n",
    "    \n",
    "    try:\n",
    "        array_KNN[i[0]]= algo_knn.estimate(int(i[1][2]), int(i[1][3]))[0]\n",
    "    except Exception as e: \n",
    "        array_KNN[i[0]]=-1000\n",
    "        knn_fail += 1\n",
    "        \n",
    "    array_NMF[i[0]] = algo_nmf.estimate(int(i[1][2])-1, int(i[1][3])-1)\n",
    "    \n",
    "    try:\n",
    "        array_SlopeOne[i[0]]=algo_slopeone.estimate(int(i[1][2]), int(i[1][3]))\n",
    "    except Exception as e: \n",
    "        array_SlopeOne[i[0]]=-1000\n",
    "        slopeone_fail += 1\n",
    "    \n",
    "    array_CoClustering[i[0]] = algo_coclustering.estimate(int(i[1][2]), int(i[1][3]))\n",
    "    if i[0]%100000==0:\n",
    "        print(i[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1549\n",
      "1549\n"
     ]
    }
   ],
   "source": [
    "print(knn_fail)\n",
    "print(slopeone_fail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
